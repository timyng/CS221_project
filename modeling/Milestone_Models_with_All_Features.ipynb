{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVR\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name', 'domain', 'year founded', 'industry', 'size range', 'city',\n",
       "       ' state', 'country', ' linkedin url', 'current employee estimate',\n",
       "       'total employee estimate', 'Score', 'reviews', 'salaries', 'interviews',\n",
       "       'KMT', 'market_cap', 'enterprise_value', 'trailing_pe', 'forward_pe',\n",
       "       'peg_ratio_5', 'price_sales', 'price_book', 'enterprise_value_revenue',\n",
       "       'enterprise_value_ebitda', 'profit_margin', 'operating_margin',\n",
       "       'return_on_assets', 'return_on_equity', 'revenue', 'revenue_per_share',\n",
       "       'quarterly_revenue_share', 'gross_profit', 'ebitda',\n",
       "       'net_income_avi_to_common', 'diluted_eps', 'quarterly_earnings_growth',\n",
       "       'total_cash', 'total_cash_per_share', 'total_dept',\n",
       "       'total_dept_per_equity', 'operating_cash_flow',\n",
       "       'leveraged_free_cash_flow', 'stock_beta_3y', 'stock 52_week',\n",
       "       'stock_sp500_52_week', 'stock_52_week_high', 'stock_52_week_low'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"../data/with_stock_data.csv\"\n",
    "frame = pd.read_csv(data_path)\n",
    "frame.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convertToClass(Y, k):\n",
    "    return Y.apply(lambda elem : np.round(elem * k / 5))\n",
    "\n",
    "# def convertToScore(Y, k):\n",
    "#     return Y.apply(lambda elem : elem * 5 / k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convertToClass(Y, k):\n",
    "    return np.apply_along_axis(lambda elem : np.round(elem * k / 5), 0, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhAAAAFkCAYAAABxWwLDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119e366d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "frame['Score']\n",
    "plt.hist(frame['Score'], alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pick Features\n",
    "non_categorical_columns = ['year founded', 'current employee estimate', 'total employee estimate', 'reviews', 'salaries', 'interviews', 'market_cap', 'enterprise_value', 'trailing_pe', 'forward_pe', 'peg_ratio_5', 'price_sales', 'price_book', 'enterprise_value_revenue', 'enterprise_value_ebitda', 'profit_margin', 'operating_margin', 'return_on_assets', 'return_on_equity', 'revenue', 'revenue_per_share', 'quarterly_revenue_share', 'gross_profit', 'ebitda', 'net_income_avi_to_common', 'diluted_eps', 'quarterly_earnings_growth', 'total_cash', 'total_cash_per_share', 'total_dept', 'total_dept_per_equity', 'operating_cash_flow', 'leveraged_free_cash_flow', 'stock_beta_3y', 'stock 52_week', 'stock_sp500_52_week', 'stock_52_week_high', 'stock_52_week_low']\n",
    "categorical_columns = ['industry', 'size range', 'city', ' state', 'country']\n",
    "# non_categorical_columns = ['trailing_pe', 'leveraged_free_cash_flow', 'operating_cash_flow', 'total_dept_per_equity', 'ebitda', 'net_income_avi_to_common', 'forward_pe', 'total_cash']\n",
    "# categorical_columns = ['city']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "le = LabelEncoder()\n",
    "X = pd.DataFrame({key : frame[key] for key in categorical_columns + non_categorical_columns})\n",
    "X[categorical_columns] = X[categorical_columns].apply(lambda col : le.fit_transform(col))\n",
    "\n",
    "for x in non_categorical_columns:\n",
    "    X[x] = X[x].fillna(X[x].mean())\n",
    "\n",
    "indices = [X.columns.get_loc(c) for c in categorical_columns]\n",
    "ohe = OneHotEncoder(categorical_features=indices, sparse=False)\n",
    "X = ohe.fit_transform(X)\n",
    "Y = pd.DataFrame({\"y\" : frame[\"Score\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error:\n",
      "0.3301463723041901\n"
     ]
    }
   ],
   "source": [
    "# Normal CV with RANDOM data\n",
    "X_random = pd.DataFrame({\"rand\" : np.random.random(Y.shape[0])})\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_random, Y, test_size=0.2)\n",
    "model = LinearRegression()\n",
    "model.fit(x_train, y_train)\n",
    "predictions = np.clip(model.predict(x_test), 0, 5)\n",
    "error = mean_squared_error(y_test, predictions)\n",
    "print(\"Mean Squared Error:\")\n",
    "print(error)\n",
    "\n",
    "# Training data\n",
    "# print(\"Training Accuracy\")\n",
    "# pred = model.predict(X)\n",
    "# print(sum(np.abs(pred - Y.values) <  0.5)/ Y.shape[0])\n",
    "# y_pred = convertToClass(pred, 10)\n",
    "# Y_scaled = convertToClass(Y, 10)\n",
    "# confusion_m = confusion_matrix(Y_scaled, y_pred)\n",
    "# print(confusion_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression (L1 Regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "reg = linear_model.Lasso(alpha=0.1)\n",
    "reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convertToClass(Y, k):\n",
    "    return np.apply_along_axis(lambda elem : np.round(elem * k / 5), 0, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Mean Square Error:\n",
      "0.33495303519549147\n",
      "Training Accuracy\n",
      "0.36030906872712487\n",
      "[[  0   0   0   0   0   1   0   0   0]\n",
      " [  0   0   0   0   0   7   0   0   0]\n",
      " [  0   0   0   0   0  55   0   0   0]\n",
      " [  0   0   0   1   0 254   0   0   0]\n",
      " [  0   0   0   0   4 609   0   0   0]\n",
      " [  0   0   0   0   5 829   4   1   0]\n",
      " [  0   0   0   0   2 491  10   3   0]\n",
      " [  0   0   0   0   2 146   2   1   0]\n",
      " [  0   0   0   0   0  31   0   0   1]]\n"
     ]
    }
   ],
   "source": [
    "# Training Data\n",
    "pred = np.clip(reg.predict(x_train), 0, 5).flatten()\n",
    "print(\"Training Mean Square Error:\")\n",
    "print(mean_squared_error(y_train, pred))\n",
    "print(\"Training Accuracy\")\n",
    "print(sum(np.abs(pred - y_train.values.flatten()) <  0.25)/ y_train.shape[0])\n",
    "y_pred = convertToClass(pred, 10)\n",
    "Y_scaled = convertToClass(y_train, 10)\n",
    "confusion_m = confusion_matrix(Y_scaled, y_pred)\n",
    "print(confusion_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Mean Square Error\n",
      "0.32098600972062186\n",
      "Test Accuracy\n",
      "0.3642276422764228\n",
      "Test Confusion Matrix\n",
      "[[  0   0   0   0   0   1   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0   0]\n",
      " [  0   0   0   0   0  12   0   0   0]\n",
      " [  0   0   0   0   0  49   0   0   0]\n",
      " [  0   0   0   0   1 173   0   0   0]\n",
      " [  0   0   0   0   2 207   3   0   0]\n",
      " [  0   0   0   0   1 115   2   0   1]\n",
      " [  0   0   0   0   0  40   0   0   0]\n",
      " [  0   0   0   0   0   6   1   0   0]]\n"
     ]
    }
   ],
   "source": [
    "# Test data: our own train / test split\n",
    "predictions = np.clip(reg.predict(x_test),0, 5).flatten()\n",
    "error = mean_squared_error(y_test, predictions)\n",
    "print(\"Test Mean Square Error\")\n",
    "print(error)\n",
    "print(\"Test Accuracy\")\n",
    "print(sum(np.abs(predictions - y_test.values.flatten()) <  0.25)/ y_test.shape[0])\n",
    "print(\"Test Confusion Matrix\")\n",
    "y_pred = convertToClass(predictions, 10)\n",
    "Y_scaled = convertToClass(y_test, 10)\n",
    "confusion_m = confusion_matrix(Y_scaled, y_pred)\n",
    "print(confusion_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression (L2 Regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "le = LabelEncoder()\n",
    "X = pd.DataFrame({key : frame[key] for key in categorical_columns + non_categorical_columns})\n",
    "X[categorical_columns] = X[categorical_columns].apply(lambda col : le.fit_transform(col))\n",
    "\n",
    "for x in non_categorical_columns:\n",
    "    X[x] = X[x].fillna(X[x].mean())\n",
    "\n",
    "indices = [X.columns.get_loc(c) for c in categorical_columns]\n",
    "ohe = OneHotEncoder(categorical_features=indices, sparse=False)\n",
    "X = ohe.fit_transform(X)\n",
    "Y = pd.DataFrame({\"y\" : frame[\"Score\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modeling\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "reg = Ridge(alpha=1.0, normalize=False)\n",
    "reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convertToClass(Y, k):\n",
    "    return np.apply_along_axis(lambda elem : np.round(elem * k / 5), 0, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Mean Square Error:\n",
      "0.18660303547765014\n",
      "Training Accuracy\n",
      "0.5115900772671818\n",
      "[[  0   0   1   0   1   0   0   0   0]\n",
      " [  0   0   0   4   1   0   0   0   0]\n",
      " [  0   0   0  22  20  12   0   0   0]\n",
      " [  0   0   0  21 145  80   2   0   0]\n",
      " [  0   0   0   4 304 304  10   0   0]\n",
      " [  0   0   0   0 108 695  48   0   0]\n",
      " [  0   0   0   0  30 327 142   1   0]\n",
      " [  0   0   0   0   2  72  62   9   0]\n",
      " [  0   0   0   0   0  13  11   7   1]]\n"
     ]
    }
   ],
   "source": [
    "# Training Data\n",
    "pred = np.clip(reg.predict(x_train), 0, 5).flatten()\n",
    "print(\"Training Mean Square Error:\")\n",
    "print(mean_squared_error(y_train, pred))\n",
    "print(\"Training Accuracy\")\n",
    "print(sum(np.abs(pred - y_train.values.flatten()) <  0.25)/ y_train.shape[0])\n",
    "y_pred = convertToClass(pred, 10)\n",
    "Y_scaled = convertToClass(y_train, 10)\n",
    "confusion_m = confusion_matrix(Y_scaled, y_pred)\n",
    "print(confusion_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Mean Square Error\n",
      "0.396556189371224\n",
      "Test Accuracy\n",
      "0.3073170731707317\n",
      "Test Confusion Matrix\n",
      "[[  0   0   0   0   3   0   0   0]\n",
      " [  0   0   0   4   8   1   0   0]\n",
      " [  0   0   3  16  35   2   0   0]\n",
      " [  0   0   2  45 108  10   0   0]\n",
      " [  0   0   4  44 124  26   2   0]\n",
      " [  0   0   3  28  80  13   1   0]\n",
      " [  0   0   0  10  31   5   0   0]\n",
      " [  0   0   0   2   3   2   0   0]]\n"
     ]
    }
   ],
   "source": [
    "# Test data: our own train / test split\n",
    "predictions = np.clip(reg.predict(x_test),0, 5).flatten()\n",
    "error = mean_squared_error(y_test, predictions)\n",
    "print(\"Test Mean Square Error\")\n",
    "print(error)\n",
    "print(\"Test Accuracy\")\n",
    "print(sum(np.abs(predictions - y_test.values.flatten()) <  0.25)/ y_test.shape[0])\n",
    "print(\"Test Confusion Matrix\")\n",
    "y_pred = convertToClass(predictions, 10)\n",
    "Y_scaled = convertToClass(y_test, 10)\n",
    "confusion_m = confusion_matrix(Y_scaled, y_pred)\n",
    "print(confusion_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "le = LabelEncoder()\n",
    "X = pd.DataFrame({key : frame[key] for key in categorical_columns + non_categorical_columns})\n",
    "X[categorical_columns] = X[categorical_columns].apply(lambda col : le.fit_transform(col))\n",
    "\n",
    "for x in non_categorical_columns:\n",
    "    X[x] = X[x].fillna(X[x].mean())\n",
    "\n",
    "indices = [X.columns.get_loc(c) for c in categorical_columns]\n",
    "ohe = OneHotEncoder(categorical_features=indices, sparse=False)\n",
    "X = ohe.fit_transform(X)\n",
    "Y = pd.DataFrame({\"y\" : frame[\"Score\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Modeling\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "reg = LinearRegression().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convertToClass(Y, k):\n",
    "    return np.apply_along_axis(lambda elem : np.round(elem * k / 5), 0, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Mean Square Error:\n",
      "0.17022880305921104\n",
      "Training Accuracy\n",
      "0.5860105734038227\n",
      "[[  0   1   0   0   1   0   0   0   0]\n",
      " [  0   1   3   2   1   0   0   0   0]\n",
      " [  0   0  16   9  18   7   0   0   0]\n",
      " [  0   0   6  88  74  67   4   0   0]\n",
      " [  0   0   0  31 320 250  23   0   0]\n",
      " [  0   0   0   6 151 591  91   3   0]\n",
      " [  0   0   0   1  30 249 217  11   0]\n",
      " [  0   0   0   0   3  60  42  49   2]\n",
      " [  0   0   0   0   0  10   5   3  13]]\n"
     ]
    }
   ],
   "source": [
    "# Training Data\n",
    "pred = np.clip(reg.predict(x_train), 0, 5).flatten()\n",
    "print(\"Training Mean Square Error:\")\n",
    "print(mean_squared_error(y_train, pred))\n",
    "print(\"Training Accuracy\")\n",
    "print(sum(np.abs(pred - y_train.values.flatten()) <  0.25)/ y_train.shape[0])\n",
    "y_pred = convertToClass(pred, 10)\n",
    "Y_scaled = convertToClass(y_train, 10)\n",
    "confusion_m = confusion_matrix(Y_scaled, y_pred)\n",
    "print(confusion_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Mean Square Error\n",
      "0.6095144411366719\n",
      "Test Accuracy\n",
      "0.2764227642276423\n",
      "Test Confusion Matrix\n",
      "[[  0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0   0]\n",
      " [  0   0   0   1   8   6   1   0   1]\n",
      " [  2   0   0   1  19  31   7   2   3]\n",
      " [  1   0   3  10  42  81  16   6   4]\n",
      " [  2   1   2  11  51 107  27   4   4]\n",
      " [  0   0   2   2  33  56  21   3   0]\n",
      " [  0   0   0   3  10  16   4   2   0]\n",
      " [  0   0   0   1   1   5   1   0   0]]\n"
     ]
    }
   ],
   "source": [
    "# Test data: our own train / test split\n",
    "predictions = np.clip(reg.predict(x_test),0, 5).flatten()\n",
    "error = mean_squared_error(y_test, predictions)\n",
    "print(\"Test Mean Square Error\")\n",
    "print(error)\n",
    "print(\"Test Accuracy\")\n",
    "print(sum(np.abs(predictions - y_test.values.flatten()) <  0.25)/ y_test.shape[0])\n",
    "print(\"Test Confusion Matrix\")\n",
    "y_pred = convertToClass(predictions, 10)\n",
    "Y_scaled = convertToClass(y_test, 10)\n",
    "confusion_m = confusion_matrix(Y_scaled, y_pred)\n",
    "print(confusion_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "le = LabelEncoder()\n",
    "X = pd.DataFrame({key : frame[key] for key in categorical_columns + non_categorical_columns})\n",
    "X[categorical_columns] = X[categorical_columns].apply(lambda col : le.fit_transform(col))\n",
    "\n",
    "for x in non_categorical_columns:\n",
    "    X[x] = X[x].fillna(X[x].mean())\n",
    "\n",
    "indices = [X.columns.get_loc(c) for c in categorical_columns]\n",
    "ohe = OneHotEncoder(categorical_features=indices, sparse=False)\n",
    "X = ohe.fit_transform(X)\n",
    "Y = pd.DataFrame({\"y\" : frame[\"Score\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Modeling\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "reg = SVR().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convertToClass(Y, k):\n",
    "    return np.apply_along_axis(lambda elem : np.round(elem * k / 5), 0, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Mean Square Error:\n",
      "0.034695133925602646\n",
      "Training Accuracy\n",
      "0.936966246441643\n",
      "[[  0   0   0   1   0   0   0   0   0]\n",
      " [  0   0   0   8   0   0   0   0   0]\n",
      " [  0   0   0  55   1   0   0   0   0]\n",
      " [  0   0   0 177  69   0   0   0   0]\n",
      " [  0   0   0  11 458 164   4   2   0]\n",
      " [  0   0   0   8   2 816   0  14   0]\n",
      " [  0   0   0   1   2 140 344   4   0]\n",
      " [  0   0   0   0   0   0  40 106   0]\n",
      " [  0   0   0   0   0   0   0  32   0]]\n"
     ]
    }
   ],
   "source": [
    "# Training Data\n",
    "pred = np.clip(reg.predict(x_train), 0, 5).flatten()\n",
    "print(\"Training Mean Square Error:\")\n",
    "print(mean_squared_error(y_train, pred))\n",
    "print(\"Training Accuracy\")\n",
    "print(sum(np.abs(pred - y_train.values.flatten()) <  0.25)/ y_train.shape[0])\n",
    "y_pred = convertToClass(pred, 10)\n",
    "Y_scaled = convertToClass(y_train, 10)\n",
    "confusion_m = confusion_matrix(Y_scaled, y_pred)\n",
    "print(confusion_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Mean Square Error\n",
      "0.33872959633143634\n",
      "Test Accuracy\n",
      "0.35609756097560974\n",
      "Test Confusion Matrix\n",
      "[[  0   0   0   0   1   0   0   0]\n",
      " [  0   0   0   0  11   0   0   0]\n",
      " [  0   0   0   0  58   0   0   0]\n",
      " [  0   0   0   1 147   0   0   0]\n",
      " [  0   0   0   0 211   0   0   0]\n",
      " [  0   0   0   0 134   0   0   0]\n",
      " [  0   0   0   1  44   0   0   0]\n",
      " [  0   0   0   0   7   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "# Test data: our own train / test split\n",
    "predictions = np.clip(reg.predict(x_test),0, 5).flatten()\n",
    "error = mean_squared_error(y_test, predictions)\n",
    "print(\"Test Mean Square Error\")\n",
    "print(error)\n",
    "print(\"Test Accuracy\")\n",
    "print(sum(np.abs(predictions - y_test.values.flatten()) <  0.25)/ y_test.shape[0])\n",
    "print(\"Test Confusion Matrix\")\n",
    "y_pred = convertToClass(predictions, 10)\n",
    "Y_scaled = convertToClass(y_test, 10)\n",
    "confusion_m = confusion_matrix(Y_scaled, y_pred)\n",
    "print(confusion_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "le = LabelEncoder()\n",
    "X = pd.DataFrame({key : frame[key] for key in categorical_columns + non_categorical_columns})\n",
    "X[categorical_columns] = X[categorical_columns].apply(lambda col : le.fit_transform(col))\n",
    "\n",
    "for x in non_categorical_columns:\n",
    "    X[x] = X[x].fillna(X[x].mean())\n",
    "\n",
    "indices = [X.columns.get_loc(c) for c in categorical_columns]\n",
    "ohe = OneHotEncoder(categorical_features=indices, sparse=False)\n",
    "X = ohe.fit_transform(X)\n",
    "Y = pd.DataFrame({\"y\" : frame[\"Score\"]})\n",
    "k = 10\n",
    "Y = convertToClass(Y, k)\n",
    "# Y[\"y\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "clf = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31720211468076454\n",
      "[[  0   0   0   0   0   0   0   1   0]\n",
      " [  0   0   0   0   1   6   1   0   0]\n",
      " [  0   0   0   0   5  37   8   1   0]\n",
      " [  0   0   0   0  37 181  22   4   0]\n",
      " [  2   0   0   0  59 485  82  14   0]\n",
      " [  0   1   0   1  91 624 106  18   0]\n",
      " [  0   0   0   0  53 329  95   8   0]\n",
      " [  0   0   0   0  27  99  27   2   0]\n",
      " [  1   0   0   0   5  21   4   1   0]]\n"
     ]
    }
   ],
   "source": [
    "# Training data\n",
    "y_pred = clf.predict(x_train)\n",
    "confusion_m = confusion_matrix(y_train, y_pred)\n",
    "training_accuracy = clf.score(x_train, y_train)\n",
    "print(training_accuracy)\n",
    "print(confusion_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3203252032520325\n",
      "[[  0   0   0   1   0   0   0   0]\n",
      " [  0   0   0   1  13   2   0   0]\n",
      " [  0   0   0   6  46   6   2   0]\n",
      " [  0   0   0  15 118   9   3   0]\n",
      " [  0   0   0  23 156  27   4   0]\n",
      " [  0   0   0  14 101  24   1   0]\n",
      " [  0   0   0   6  22   6   2   0]\n",
      " [  0   0   0   3   3   1   0   0]]\n"
     ]
    }
   ],
   "source": [
    "# Testing data\n",
    "y_pred = clf.predict(x_test)\n",
    "confusion_m = confusion_matrix(y_test, y_pred)\n",
    "test_accuracy = clf.score(x_test, y_test)\n",
    "print(test_accuracy)\n",
    "print(confusion_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine, Kernel = rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "le = LabelEncoder()\n",
    "X = pd.DataFrame({key : frame[key] for key in categorical_columns + non_categorical_columns})\n",
    "X[categorical_columns] = X[categorical_columns].apply(lambda col : le.fit_transform(col))\n",
    "\n",
    "for x in non_categorical_columns:\n",
    "    X[x] = X[x].fillna(X[x].mean())\n",
    "\n",
    "indices = [X.columns.get_loc(c) for c in categorical_columns]\n",
    "ohe = OneHotEncoder(categorical_features=indices, sparse=False)\n",
    "X = ohe.fit_transform(X)\n",
    "Y = pd.DataFrame({\"y\" : frame[\"Score\"]})\n",
    "k = 10\n",
    "Y = convertToClass(Y, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=0.8, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "clf = SVC(gamma = 'auto', kernel='rbf', C=.8)\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9015860105734038\n",
      "[[  0   0   0   0   0   2   0   0   0]\n",
      " [  0   0   0   0   0   7   0   0   0]\n",
      " [  0   0   0   0   0  56   0   0   0]\n",
      " [  0   0   0 232   0   2   0   0   0]\n",
      " [  0   0   0   0 623   0   0   0   0]\n",
      " [  0   0   0   0   0 857   0   0   0]\n",
      " [  0   0   0   0   0   2 503   0   0]\n",
      " [  0   0   0   0   0 144   0   2   0]\n",
      " [  0   0   0   0   0  29   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "# Training data\n",
    "y_pred = clf.predict(x_train)\n",
    "confusion_m = confusion_matrix(y_train, y_pred)\n",
    "training_accuracy = clf.score(x_train, y_train)\n",
    "print(training_accuracy)\n",
    "print(confusion_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3154471544715447\n",
      "[[  0   0   0   0   1   0   0   0]\n",
      " [  0   0   0   0  11   0   0   0]\n",
      " [  0   0   0   0  70   0   0   0]\n",
      " [  0   0   0   0 164   0   0   0]\n",
      " [  0   0   0   0 194   0   0   0]\n",
      " [  0   0   0   0 120   0   0   0]\n",
      " [  0   0   0   0  45   0   0   0]\n",
      " [  0   0   0   0  10   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "# Testing data\n",
    "y_pred = clf.predict(x_test)\n",
    "confusion_m = confusion_matrix(y_test, y_pred)\n",
    "test_accuracy = clf.score(x_test, y_test)\n",
    "print(test_accuracy)\n",
    "print(confusion_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine, Kernel = linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "le = LabelEncoder()\n",
    "X = pd.DataFrame({key : frame[key] for key in categorical_columns + non_categorical_columns})\n",
    "X[categorical_columns] = X[categorical_columns].apply(lambda col : le.fit_transform(col))\n",
    "\n",
    "for x in non_categorical_columns:\n",
    "    X[x] = X[x].fillna(X[x].mean())\n",
    "\n",
    "indices = [X.columns.get_loc(c) for c in categorical_columns]\n",
    "ohe = OneHotEncoder(categorical_features=indices, sparse=False)\n",
    "X = ohe.fit_transform(X)\n",
    "Y = pd.DataFrame({\"y\" : frame[\"Score\"]})\n",
    "k = 10\n",
    "Y = convertToClass(Y, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=5000, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "clf = SVC(gamma = 'auto', kernel='linear', C=1, max_iter=5000)\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11793411956079707\n",
      "[[  0   0   0   2   0   0   0   0   0]\n",
      " [  0   0   0   7   1   0   0   0   0]\n",
      " [  0   0   0  39   0   1   1   1   4]\n",
      " [  0   2   1 212   9   4   6   3   8]\n",
      " [  0   9  12 516  31   7  22  11  10]\n",
      " [  0  15  18 649  58  13  39  22  20]\n",
      " [  0   7  23 395  28   3  31  18  14]\n",
      " [  0   2   3 128   7   2   3   1   8]\n",
      " [  0   0   2  28   0   0   1   0   2]]\n"
     ]
    }
   ],
   "source": [
    "# Training data\n",
    "y_pred = clf.predict(x_train)\n",
    "confusion_m = confusion_matrix(y_train, y_pred)\n",
    "training_accuracy = clf.score(x_train, y_train)\n",
    "print(training_accuracy)\n",
    "print(confusion_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11707317073170732\n",
      "[[  0   0   0   0   0   0   0   0]\n",
      " [  0   0  17   4   0   0   0   0]\n",
      " [  1   1  53   1   0   2   0   1]\n",
      " [  2   1 145  10   1   3   2   5]\n",
      " [  5   9 166  18   1  12   4   2]\n",
      " [  2   4  82   7   0   6   4   1]\n",
      " [  0   0  29   3   1   3   1   0]\n",
      " [  0   0   5   0   0   0   0   1]]\n"
     ]
    }
   ],
   "source": [
    "# Testing data\n",
    "y_pred = clf.predict(x_test)\n",
    "confusion_m = confusion_matrix(y_test, y_pred)\n",
    "test_accuracy = clf.score(x_test, y_test)\n",
    "print(test_accuracy)\n",
    "print(confusion_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "le = LabelEncoder()\n",
    "X = pd.DataFrame({key : frame[key] for key in categorical_columns + non_categorical_columns})\n",
    "X[categorical_columns] = X[categorical_columns].apply(lambda col : le.fit_transform(col))\n",
    "\n",
    "for x in non_categorical_columns:\n",
    "    X[x] = X[x].fillna(X[x].mean())\n",
    "\n",
    "indices = [X.columns.get_loc(c) for c in categorical_columns]\n",
    "ohe = OneHotEncoder(categorical_features=indices, sparse=False)\n",
    "X = ohe.fit_transform(X)\n",
    "Y = pd.DataFrame({\"y\" : frame[\"Score\"]})\n",
    "k = 10\n",
    "Y = convertToClass(Y, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=15,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "clf = tree.DecisionTreeClassifier(max_depth = 15)\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7710451403009353\n",
      "[[  1   0   0   0   0   0   0   0   0]\n",
      " [  0   2   1   0   0   3   0   2   0]\n",
      " [  0   0  32   0  11  11   1   1   0]\n",
      " [  0   0   2 134  15  70   1   2   0]\n",
      " [  0   0   1  12 487 136   6   1   0]\n",
      " [  0   0   1  15  28 796  14   2   0]\n",
      " [  0   0   0  12  25 118 335   1   0]\n",
      " [  0   0   1   5  17  41   1  81   0]\n",
      " [  0   0   1   1   0   4   0   0  28]]\n"
     ]
    }
   ],
   "source": [
    "# Training data\n",
    "y_pred = clf.predict(x_train)\n",
    "confusion_m = confusion_matrix(y_train, y_pred)\n",
    "training_accuracy = clf.score(x_train, y_train)\n",
    "print(training_accuracy)\n",
    "print(confusion_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28292682926829266\n",
      "[[  0   0   0   1   0   0   0   0]\n",
      " [  0   0   0   2   7   2   0   0]\n",
      " [  0   0   2  30  37   9   1   1]\n",
      " [  0   3  16  33  62  27   3   0]\n",
      " [  0   1   8  42 108  32   4   0]\n",
      " [  0   2   9  28  57  28   8   2]\n",
      " [  0   1   5  13  14   9   3   0]\n",
      " [  0   0   1   1   2   1   0   0]]\n"
     ]
    }
   ],
   "source": [
    "# Testing data\n",
    "y_pred = clf.predict(x_test)\n",
    "confusion_m = confusion_matrix(y_test, y_pred)\n",
    "test_accuracy = clf.score(x_test, y_test)\n",
    "print(test_accuracy)\n",
    "print(confusion_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "le = LabelEncoder()\n",
    "X = pd.DataFrame({key : frame[key] for key in categorical_columns + non_categorical_columns})\n",
    "X[categorical_columns] = X[categorical_columns].apply(lambda col : le.fit_transform(col))\n",
    "\n",
    "for x in non_categorical_columns:\n",
    "    X[x] = X[x].fillna(X[x].mean())\n",
    "\n",
    "indices = [X.columns.get_loc(c) for c in categorical_columns]\n",
    "ohe = OneHotEncoder(categorical_features=indices, sparse=False)\n",
    "X = ohe.fit_transform(X)\n",
    "Y = pd.DataFrame({\"y\" : frame[\"Score\"]})\n",
    "k = 10\n",
    "Y = convertToClass(Y, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "              solver='svd', store_covariance=False, tol=0.0001)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "clf = LinearDiscriminantAnalysis()\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7002846685644571\n",
      "[[  1   0   0   0   0   1   0   0   0]\n",
      " [  0   6   0   0   1   0   0   0   0]\n",
      " [  0   0  39   1   4   4   7   1   0]\n",
      " [  0   0   3 150  30  24  23   3   0]\n",
      " [  0   0   2  17 486  63  65   8   1]\n",
      " [  0   1   4  13 118 546 123  21   5]\n",
      " [  0   0   1  10  49  50 393   7   1]\n",
      " [  0   0   0   1  17  19  25  85   0]\n",
      " [  0   0   0   0   4   5   5   0  16]]\n"
     ]
    }
   ],
   "source": [
    "# Training data\n",
    "y_pred = clf.predict(x_train)\n",
    "confusion_m = confusion_matrix(y_train, y_pred)\n",
    "training_accuracy = clf.score(x_train, y_train)\n",
    "print(training_accuracy)\n",
    "print(confusion_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26991869918699185\n",
      "[[ 0  0  0  0  1  0  0  0]\n",
      " [ 0  0  0  3  4  2  2  0]\n",
      " [ 0  1  7 18 20 19  6  0]\n",
      " [ 0 10 10 41 41 30 13  0]\n",
      " [ 0 10 12 56 68 55 18  1]\n",
      " [ 0  3  6 26 27 43  9  0]\n",
      " [ 0  3  3 13  6 12  7  0]\n",
      " [ 0  0  1  2  3  3  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# Testing data\n",
    "y_pred = clf.predict(x_test)\n",
    "confusion_m = confusion_matrix(y_test, y_pred)\n",
    "test_accuracy = clf.score(x_test, y_test)\n",
    "print(test_accuracy)\n",
    "print(confusion_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "le = LabelEncoder()\n",
    "X = pd.DataFrame({key : frame[key] for key in categorical_columns + non_categorical_columns})\n",
    "X[categorical_columns] = X[categorical_columns].apply(lambda col : le.fit_transform(col))\n",
    "\n",
    "for x in non_categorical_columns:\n",
    "    X[x] = X[x].fillna(X[x].mean())\n",
    "\n",
    "indices = [X.columns.get_loc(c) for c in categorical_columns]\n",
    "ohe = OneHotEncoder(categorical_features=indices, sparse=False)\n",
    "X = ohe.fit_transform(X)\n",
    "Y = pd.DataFrame({\"y\" : frame[\"Score\"]})\n",
    "k = 10\n",
    "Y = convertToClass(Y, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:695: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
       "               store_covariances=False, tol=0.0001)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "clf = QuadraticDiscriminantAnalysis()\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47132980886539244\n",
      "[[  1   0   0   0   0   1   0   0   0]\n",
      " [  0   3   0   0   1   2   0   0   0]\n",
      " [  0   0  19   1   2  17   1   5   2]\n",
      " [  0   0   0 142   4  93   2   0   0]\n",
      " [  0   0 146   3 112 231  25  85  35]\n",
      " [  0   0 109   2   3 614   8  87  17]\n",
      " [  0   0  44   4   4 202 204  35   5]\n",
      " [  0   0  26   5   5  64   7  50   5]\n",
      " [  0   0   0   0   0  12   0   0  14]]\n"
     ]
    }
   ],
   "source": [
    "# Training data\n",
    "y_pred = clf.predict(x_train)\n",
    "confusion_m = confusion_matrix(y_train, y_pred)\n",
    "training_accuracy = clf.score(x_train, y_train)\n",
    "print(training_accuracy)\n",
    "print(confusion_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18048780487804877\n",
      "[[ 0  1  0  0  0  0  0  1]\n",
      " [ 0  6  0  1  4  0  6  3]\n",
      " [ 0 17  1  2 22  1 13  7]\n",
      " [ 0 50  4  7 56  5 22  6]\n",
      " [ 0 52  5  4 86  7 42 15]\n",
      " [ 0 37  1  1 54  6 21  7]\n",
      " [ 0  5  1  0 15  1  5  2]\n",
      " [ 0  2  0  0  7  0  4  0]]\n"
     ]
    }
   ],
   "source": [
    "# Testing data\n",
    "y_pred = clf.predict(x_test)\n",
    "confusion_m = confusion_matrix(y_test, y_pred)\n",
    "test_accuracy = clf.score(x_test, y_test)\n",
    "print(test_accuracy)\n",
    "print(confusion_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "le = LabelEncoder()\n",
    "X = pd.DataFrame({key : frame[key] for key in categorical_columns + non_categorical_columns})\n",
    "X[categorical_columns] = X[categorical_columns].apply(lambda col : le.fit_transform(col))\n",
    "\n",
    "for x in non_categorical_columns:\n",
    "    X[x] = X[x].fillna(X[x].mean())\n",
    "\n",
    "indices = [X.columns.get_loc(c) for c in categorical_columns]\n",
    "ohe = OneHotEncoder(categorical_features=indices, sparse=False)\n",
    "X = ohe.fit_transform(X)\n",
    "Y = pd.DataFrame({\"y\" : frame[\"Score\"]})\n",
    "k = 10\n",
    "Y = convertToClass(Y, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=20, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "neigh = KNeighborsClassifier(n_neighbors=20)\n",
    "neigh.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3867425782838552\n",
      "[[  0   0   0   0   0   2   0   0   0]\n",
      " [  0   0   0   0   2   4   1   0   0]\n",
      " [  0   0   0   1  19  23   7   0   0]\n",
      " [  0   0   0  16  77 125  35   0   0]\n",
      " [  0   0   0  17 280 274  64   0   0]\n",
      " [  0   0   0  16 200 506  96   0   0]\n",
      " [  0   0   0  12 134 220 149   0   0]\n",
      " [  0   0   0   1  45  64  38   0   0]\n",
      " [  0   0   0   0   8  19   4   0   0]]\n"
     ]
    }
   ],
   "source": [
    "# Training data\n",
    "y_pred = neigh.predict(x_train)\n",
    "confusion_m = confusion_matrix(y_train, y_pred)\n",
    "training_accuracy = neigh.score(x_train, y_train)\n",
    "print(training_accuracy)\n",
    "print(confusion_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3056910569105691\n",
      "[[  0   0   0   1   0   0   0   0]\n",
      " [  0   0   1   6   8   2   0   0]\n",
      " [  0   0   0  15  25  11   0   0]\n",
      " [  0   0   4  48  79  21   0   0]\n",
      " [  0   0   5  71 118  39   0   0]\n",
      " [  0   0   2  29  57  22   0   0]\n",
      " [  0   0   1  12  21   9   0   0]\n",
      " [  0   0   0   2   4   2   0   0]]\n"
     ]
    }
   ],
   "source": [
    "# Testing data\n",
    "y_pred = neigh.predict(x_test)\n",
    "confusion_m = confusion_matrix(y_test, y_pred)\n",
    "test_accuracy = neigh.score(x_test, y_test)\n",
    "print(test_accuracy)\n",
    "print(confusion_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "le = LabelEncoder()\n",
    "X = pd.DataFrame({key : frame[key] for key in categorical_columns + non_categorical_columns})\n",
    "X[categorical_columns] = X[categorical_columns].apply(lambda col : le.fit_transform(col))\n",
    "\n",
    "for x in non_categorical_columns:\n",
    "    X[x] = X[x].fillna(X[x].mean())\n",
    "\n",
    "indices = [X.columns.get_loc(c) for c in categorical_columns]\n",
    "ohe = OneHotEncoder(categorical_features=indices, sparse=False)\n",
    "X = ohe.fit_transform(X)\n",
    "Y = pd.DataFrame({\"y\" : frame[\"Score\"]})\n",
    "k = 10\n",
    "Y = convertToClass(Y, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "pca = PCA(n_components=5)\n",
    "X_new = pca.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=0.8, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC(gamma = 'auto', kernel='rbf', C=.8)\n",
    "clf.fit(X_new, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8271655144367629\n",
      "[[  0   0   0   0   0   2   0   0   0]\n",
      " [  0   0   0   0   1   4   1   0   0]\n",
      " [  0   0   0   2   6  49   2   0   0]\n",
      " [  0   0   0 199  14  21   6   0   0]\n",
      " [  0   0   0   1 587  46   2   0   0]\n",
      " [  0   0   0   0  14 821   3   0   0]\n",
      " [  0   0   0   0  32  40 427   0   0]\n",
      " [  0   0   0   5  13 121   9   0   0]\n",
      " [  0   0   0   0   5  25   1   0   0]]\n"
     ]
    }
   ],
   "source": [
    "# Training data\n",
    "y_pred = clf.predict(X_new)\n",
    "confusion_m = confusion_matrix(y_train, y_pred)\n",
    "training_accuracy = clf.score(X_new, y_train)\n",
    "print(training_accuracy)\n",
    "print(confusion_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3170731707317073\n",
      "[[  0   0   0   0   2   0   0   0]\n",
      " [  0   0   0   1   6   1   0   0]\n",
      " [  0   0   1   4  55   4   0   0]\n",
      " [  0   0  10  11 121   9   0   0]\n",
      " [  0   0   7  21 174  11   0   0]\n",
      " [  0   0   2   7 108   9   0   0]\n",
      " [  0   0   0   4  35   4   0   0]\n",
      " [  0   0   0   1   7   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "# Testing data\n",
    "X_new_test = pca.transform(x_test)\n",
    "y_pred = clf.predict(X_new_test)\n",
    "confusion_m = confusion_matrix(y_test, y_pred)\n",
    "test_accuracy = clf.score(X_new_test, y_test)\n",
    "print(test_accuracy)\n",
    "print(confusion_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "le = LabelEncoder()\n",
    "X = pd.DataFrame({key : frame[key] for key in categorical_columns + non_categorical_columns})\n",
    "X[categorical_columns] = X[categorical_columns].apply(lambda col : le.fit_transform(col))\n",
    "\n",
    "for x in non_categorical_columns:\n",
    "    X[x] = X[x].fillna(X[x].mean())\n",
    "\n",
    "indices = [X.columns.get_loc(c) for c in categorical_columns]\n",
    "ohe = OneHotEncoder(categorical_features=indices, sparse=False)\n",
    "X = ohe.fit_transform(X)\n",
    "Y = pd.DataFrame({\"y\" : frame[\"Score\"]})\n",
    "k = 10\n",
    "Y = convertToClass(Y, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:904: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100, 100, 100), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100, 100, 100), random_state=1)\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.054087027246848315\n",
      "[[  1   1   0   0   0   0   0   0   0]\n",
      " [  2   1   4   0   0   0   0   0   0]\n",
      " [ 16  15  14   0   0   3   1   6   0]\n",
      " [ 66  70  53   0   0  28   9  14   0]\n",
      " [178 165 131   4   0  79  28  31   0]\n",
      " [294 237 158   6   0  90  29  44   0]\n",
      " [191 123  91   1   0  55  17  24   0]\n",
      " [ 46  30  35   0   0  24   3  10   0]\n",
      " [  7   9   7   0   0   2   3   3   0]]\n"
     ]
    }
   ],
   "source": [
    "# Training data\n",
    "y_pred = clf.predict(x_train)\n",
    "confusion_m = confusion_matrix(y_train, y_pred)\n",
    "training_accuracy = clf.score(x_train, y_train)\n",
    "print(training_accuracy)\n",
    "print(confusion_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05040650406504065\n",
      "[[ 0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0]\n",
      " [ 1  3  5  0  0  0  0  3  0]\n",
      " [20 14 15  0  0 10  1  4  0]\n",
      " [57 50 33  0  0 14  9  8  0]\n",
      " [62 52 36  1  0 19 13 10  0]\n",
      " [50 25 23  1  0 12  6  6  0]\n",
      " [15 11 12  0  0  4  0  1  0]\n",
      " [ 4  1  1  0  0  1  0  1  0]]\n"
     ]
    }
   ],
   "source": [
    "# Testing data\n",
    "y_pred = clf.predict(x_test)\n",
    "confusion_m = confusion_matrix(y_test, y_pred)\n",
    "test_accuracy = clf.score(x_test, y_test)\n",
    "print(test_accuracy)\n",
    "print(confusion_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
